{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from os import path, listdir\n",
    "\n",
    "# Define the function to load the dataset\n",
    "def load_image_dataset(file_path):\n",
    "    all_image_dirs = [os.path.join(file_path, f) for f in os.listdir(file_path) if not os.path.isdir(os.path.join(file_path, f))]\n",
    "    all_image_labels = []\n",
    "    for f in all_image_dirs:\n",
    "        if \"cat\" in f:\n",
    "            all_image_labels.append(0)\n",
    "        else:\n",
    "            all_image_labels.append(1)\n",
    "    return all_image_dirs, all_image_labels\n",
    "\n",
    "# Load dataset\n",
    "train_path = r\"C:/Users/LENOVO/Desktop/mlflowshit/data/train\"\n",
    "all_image_dirs, all_image_labels = load_image_dataset(train_path)\n",
    "\n",
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"dog-cat-classification-optimizer-comparison\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "num_train_image = int(len(all_image_labels) * 0.8)\n",
    "train_image_dirs, train_label = all_image_dirs[:num_train_image], all_image_labels[:num_train_image]\n",
    "test_image_dirs, test_label = all_image_dirs[num_train_image:], all_image_labels[num_train_image:]\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_path_label = tf.data.Dataset.from_tensor_slices((train_image_dirs, train_label))\n",
    "test_path_label = tf.data.Dataset.from_tensor_slices((test_image_dirs, test_label))\n",
    "\n",
    "# Define the image preprocessing function\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0\n",
    "    image = 2 * image - 1\n",
    "    return image\n",
    "\n",
    "# Prepare the training and testing datasets\n",
    "train_image_label_ds = train_path_label.map(lambda x, y: (load_and_preprocess_image(x), y))\n",
    "test_image_label_ds = test_path_label.map(lambda x, y: (load_and_preprocess_image(x), y)).batch(1)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model(optimizer):\n",
    "    mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "    mobile_net.trainable = False\n",
    "    cnn_model = keras.models.Sequential([\n",
    "        mobile_net,\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(2, activation=\"softmax\")\n",
    "    ])\n",
    "    cnn_model.compile(optimizer=optimizer,\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=[\"accuracy\"])\n",
    "    return cnn_model\n",
    "\n",
    "# Define optimizer variations\n",
    "optimizers = [tf.keras.optimizers.Adam(), tf.keras.optimizers.SGD(), tf.keras.optimizers.RMSprop()]\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "steps_per_epoch = len(train_image_dirs) // BATCH_SIZE\n",
    "\n",
    "# Train models with different optimizers and log results\n",
    "for optimizer in optimizers:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"optimizer\", optimizer.__class__.__name__)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        \n",
    "        # Create and fit the model\n",
    "        cnn_model = create_model(optimizer)\n",
    "        train_ds = train_image_label_ds.shuffle(buffer_size=len(train_image_dirs)).repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "        history = cnn_model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", history.history['accuracy'][-1])\n",
    "        mlflow.log_metric(\"loss\", history.history['loss'][-1])\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.keras.log_model(cnn_model, \"model\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
