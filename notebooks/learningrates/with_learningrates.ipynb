{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from os import path, listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dataset(file_path):\n",
    "    all_image_dirs = [os.path.join(file_path, f) for f in os.listdir(file_path) if not os.path.isdir(os.path.join(file_path, f))]\n",
    "    all_image_labels = []\n",
    "    for f in all_image_dirs:\n",
    "        if \"cat\" in f:\n",
    "            all_image_labels.append(0)\n",
    "        else:\n",
    "            all_image_labels.append(1)\n",
    "    return all_image_dirs, all_image_labels\n",
    "\n",
    "# Provide the correct path to your dataset\n",
    "train_path = r\"C:/Users/LENOVO/Desktop/mlflowshit/data/train\"\n",
    "all_image_dirs, all_image_labels = load_image_dataset(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_image = int(len(all_image_labels) * 0.8 // 1)\n",
    "train_image_dirs, train_label = all_image_dirs[:num_train_image], all_image_labels[:num_train_image]\n",
    "test_image_dirs, test_label = all_image_dirs[num_train_image:], all_image_labels[num_train_image:]\n",
    "\n",
    "train_path_label = tf.data.Dataset.from_tensor_slices((train_image_dirs, train_label))\n",
    "test_path_label = tf.data.Dataset.from_tensor_slices((test_image_dirs, test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0  # Normalization to [0,1]\n",
    "    image = 2 * image - 1  # Normalize to [-1,1]\n",
    "    return image\n",
    "\n",
    "train_image_label_ds = train_path_label.map(lambda x, y: (load_and_preprocess_image(x), y))\n",
    "test_image_label_ds = test_path_label.map(lambda x, y: (load_and_preprocess_image(x), y)).batch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2 and add layers on top\n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable = False  # Freeze the base model\n",
    "\n",
    "# Build a custom Sequential model\n",
    "cnn_model = keras.models.Sequential([\n",
    "    mobile_net,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "steps_per_epoch = len(train_image_dirs) // BATCH_SIZE\n",
    "\n",
    "train_ds = train_image_label_ds.shuffle(buffer_size=len(train_image_dirs))\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 588ms/step - accuracy: 0.9771 - loss: 0.0672\n",
      "Epoch 2/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 698ms/step - accuracy: 0.9903 - loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/28 01:15:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/28 01:17:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 611ms/step - accuracy: 0.9953 - loss: 0.0149\n",
      "Epoch 2/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 660ms/step - accuracy: 0.9966 - loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/28 01:33:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/28 01:34:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.0001]  #  learning rates to experiment with\n",
    "\n",
    "for lr in learning_rates:\n",
    "    with mlflow.start_run():\n",
    "        # Log parameters for the current run\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "\n",
    "        # Compile model with the new learning rate\n",
    "        cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "        # Train the model\n",
    "        history = cnn_model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "        # Log accuracy and loss metrics\n",
    "        mlflow.log_metric(\"accuracy\", history.history['accuracy'][-1])\n",
    "        mlflow.log_metric(\"loss\", history.history['loss'][-1])\n",
    "\n",
    "        # Log the model in MLflow\n",
    "        mlflow.keras.log_model(cnn_model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the runs and sort by accuracy to get the best model\n",
    "best_run = mlflow.search_runs(order_by=[\"metrics.accuracy DESC\"]).iloc[0]\n",
    "\n",
    "# Get the URI of the best model\n",
    "best_model_uri = best_run.artifact_uri + \"/model\"\n",
    "\n",
    "# Load the best model\n",
    "best_model = mlflow.keras.load_model(best_model_uri)\n",
    "\n",
    "# You can now use `best_model` for making predictions or further testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
