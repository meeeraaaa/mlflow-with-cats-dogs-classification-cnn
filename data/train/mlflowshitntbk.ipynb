{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install ipykernel\n",
    "#!{sys.executable} -m ipykernel install --user --name=.venv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mlflow\n",
    "#print(mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/LENOVO/Desktop/mlflowshit/mlruns/155574306472953328', creation_time=1730046646775, experiment_id='155574306472953328', last_update_time=1730046646775, lifecycle_stage='active', name='dog-cat-classification', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from os import path, listdir\n",
    "\n",
    "def load_image_dataset(file_path):\n",
    "    all_image_dirs = [os.path.join(file_path, f) for f in os.listdir(file_path) if not os.path.isdir(os.path.join(file_path, f))]\n",
    "    all_image_labels = []\n",
    "    for f in all_image_dirs:\n",
    "        if \"cat\" in f:\n",
    "            all_image_labels.append(0)\n",
    "        else:\n",
    "            all_image_labels.append(1)\n",
    "    return all_image_dirs, all_image_labels\n",
    "\n",
    "train_path = r\"C:/Users/LENOVO/Desktop/mlflowshit/data/train\"\n",
    "all_image_dirs, all_image_labels = load_image_dataset(train_path)\n",
    "\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_experiment(\"dog-cat-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_image = int(len(all_image_labels)*0.8//1)\n",
    "train_image_dirs, train_label = all_image_dirs[:num_train_image], all_image_labels[:num_train_image]\n",
    "test_image_dirs, test_label = all_image_dirs[num_train_image:], all_image_labels[num_train_image:]\n",
    "\n",
    "train_path_label = tf.data.Dataset.from_tensor_slices((train_image_dirs, train_label))\n",
    "test_path_label = tf.data.Dataset.from_tensor_slices((test_image_dirs, test_label))\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192, 192])\n",
    "    image /= 255.0\n",
    "    image = 2*image-1\n",
    "    return image\n",
    "\n",
    "train_image_label_ds = train_path_label.map(lambda x, y: (load_and_preprocess_image(x), y))\n",
    "test_image_label_ds = test_path_label.map(lambda x, y: (load_and_preprocess_image(x), y)).batch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable = False\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "    mobile_net,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 584ms/step - accuracy: 0.9747 - loss: 0.0752\n",
      "Epoch 2/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 875ms/step - accuracy: 0.9889 - loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/28 00:57:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/28 00:57:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpb9n6zlns\\model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/10/28 00:57:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "steps_per_epoch = len(train_image_dirs) // BATCH_SIZE\n",
    "\n",
    "train_ds = train_image_label_ds.shuffle(buffer_size=len(train_image_dirs))\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "\n",
    "    history = cnn_model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", history.history['accuracy'][-1])\n",
    "    mlflow.log_metric(\"loss\", history.history['loss'][-1])\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.keras.log_model(cnn_model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the runs and sort by accuracy to get the best model\n",
    "best_run = mlflow.search_runs(order_by=[\"metrics.accuracy DESC\"]).iloc[0]\n",
    "\n",
    "# Get the URI of the best model\n",
    "best_model_uri = best_run.artifact_uri + \"/model\"\n",
    "\n",
    "# Load the best model\n",
    "best_model = mlflow.keras.load_model(best_model_uri)\n",
    "\n",
    "# You can now use `best_model` for making predictions or further testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('my_model.h5')\n",
    "mlflow.keras.log_model(cnn_model, \"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
